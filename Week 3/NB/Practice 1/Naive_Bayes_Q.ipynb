{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LijPfBPXkebb"
   },
   "source": [
    "# Bài toán phân loại sử dụng Naive Bayes \n",
    "\n",
    "Mục tiêu: \n",
    "\n",
    "- Xây dựng được mô hình nb sử dụng thư viện sklearn. \n",
    "- Ứng dụng, hiểu cách áp dụng mô hình nb vào giải quyết bài toán thực tế (vd: phân loại văn bản) \n",
    "- Sử dụng độ đo Accuracy để làm độ đo đánh giá chất lượng mô hình. \n",
    "\n",
    "Vấn đề: \n",
    "- Có một tập các văn bản dạng text không có nhãn, làm sao để biết văn bản này là thuộc về thể loại nào, pháp luật, đời sống, văn học, thể thao ...\n",
    "- => Xây dựng mô hình học máy có thể phân loại các thể loại của văn bản chỉ dựa trên nội dung.  \n",
    "\n",
    "Dữ liệu: \n",
    "- Có tập các văn bản và nhãn tương ứng của từng văn bản trong một khoảng thời gian \n",
    "- Tập các nhãn - 10 nhãn văn bản: \n",
    "    > Giải trí, Khoa học - Công nghệ, Kinh tế, Pháp luật, Sức khỏe, Thể thao, Thời sự, Tin khác, Độc giả, Đời sống - Xã hội\n",
    "- Ví dụ văn bản nhãn **thể thao**: \n",
    "    > \"Dân_trí Real Madrid đã dẫn trước trong cả trận đấu , nhưng họ vẫn phải chấp_nhận bị Dortmund cầm hòa 2-2 ở Bernabeu . Real Madrid chấp_nhận đứng thứ_hai ở bảng F Champions League ...\"\n",
    "\n",
    "Bài toán: \n",
    "- Input: tập các từ trong văn bản 1 mẫu dữ liệu $X = [x_1, x_2, ... x_n]$\n",
    "- Output: nhãn $y$ là 1 trong 10 nhãn trên "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IqGqHaHZ6FU0"
   },
   "source": [
    "# Nội dung thực hành"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82jlDZZj6H0z"
   },
   "source": [
    "1. Nếu sử dụng GColab, cần kết nối với server và Gdrive(nếu sử dụng dữ liệu trong drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZfqLntit-1cX",
    "outputId": "843db4ea-d178-4f1e-d9af-7e84a580efc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "65aXLXKd_2O7",
    "outputId": "7d2fbc5c-edf7-4994-ae21-7645e1a82578"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/NB_practice/1. Practice\n"
     ]
    }
   ],
   "source": [
    "cd /content/drive/MyDrive/NB_practice/1. Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pj1pLKZ86TDH"
   },
   "source": [
    "2. Import các thư viện cần thiết, cài thêm một số thư viện chưa sẵn có"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QxQXkouYkebh",
    "outputId": "c7a6d0eb-2254-48be-c761-e9804b486d9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyvi in /usr/local/lib/python3.7/dist-packages (0.1.1)\n",
      "Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.7/dist-packages (from pyvi) (0.3.6)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyvi) (0.22.2.post1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.0.1)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (0.8.9)\n",
      "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (4.62.0)\n",
      "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (0.9.7)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "# Cài đặt thư viện xử lý ngôn ngữ cho tiếng Việt!\n",
    "!pip install pyvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "lKp1z1cHkebk"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#from sklearn.datasets import load_files\n",
    "from pyvi import ViTokenizer # Tách từ tiếng Việt\n",
    "\n",
    "\n",
    "import sklearn.naive_bayes as naive_bayes\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-qNL6tkkebl"
   },
   "source": [
    "3. Load dữ liệu từ thư mục đã crawl từ trước \n",
    "\n",
    ">Cấu trúc thư mục như sau \n",
    "- data/news_1135/\n",
    "    - Kinh tế: \n",
    "        - bài báo 1.txt \n",
    "        - bài báo 2.txt \n",
    "    - Pháp luật\n",
    "        - bài báo 3.txt \n",
    "        - bài báo 4.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Z3C3XqNkebm",
    "outputId": "88a99e42-85ed-4533-cbb1-619b6f4e6fae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/news_1135/Thể thao/2e62de81ade8318f66cc740f5ede5607ea1bf002.txt'\n",
      " 'data/news_1135/Thể thao/f9bd156031140a7db52ae51de4561f234a0eb277.txt'\n",
      " 'data/news_1135/Thể thao/aeeb3b3b0dfc936de928f0b004259aca70aa4efa.txt']\n",
      "\n",
      "Tong so file: 224\n",
      "Danh sách 10 nhãn và id tương ứng:  [(0, 'Giải trí'), (1, 'Khoa học - Công nghệ'), (2, 'Kinh tế'), (3, 'Pháp luật'), (4, 'Sức khỏe'), (5, 'Thể thao'), (6, 'Thời sự')]\n"
     ]
    }
   ],
   "source": [
    "data_train = load_files(container_path=\"data/news_1135/\", encoding=\"utf-8\")\n",
    "\n",
    "print(data_train.filenames[0:3])\n",
    "print()\n",
    "\n",
    "print(\"Tong so file: {}\" .format( len(data_train.filenames)))\n",
    "print(\"Danh sách 10 nhãn và id tương ứng: \", [(idx, name) for idx, name in enumerate(data_train.target_names[0:10])] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JA2ZGlfykebo"
   },
   "outputs": [],
   "source": [
    "### bài tập ### \n",
    "# yêu cầu: Hiển thị nội dung, và nhãn của văn bản đầu tiên trong tập train. \n",
    "# gợi ý: tự làm.  \n",
    "###############\n",
    "# code \n",
    "\n",
    "\n",
    "###############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XV0pQNzBkebp"
   },
   "source": [
    "##  Tiền xử lý dữ liệu đưa dữ liệu từ dạng text về dạng ma trận \n",
    "\n",
    "- Thử nghiệm để kiểm tra hoạt động chuyển hoá dữ liệu về dạng ma trận "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SS12JkxRkebp",
    "outputId": "f7a8fae8-4028-466e-84b4-110bef871cee",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Danh sách 10 từ dừng đầu tiên (từ không mang ý nghĩa phân loại):  ['a_lô', 'a_ha', 'ai', 'ai_ai', 'ai_nấy', 'ai_đó', 'alô', 'amen', 'anh', 'anh_ấy']\n",
      "\n",
      "10 từ đầu tiên trong từ điển:\n",
      "\n",
      "1 :  ('dân_trí', 1910)\n",
      "2 :  ('12', 31)\n",
      "3 :  ('giải', 2248)\n",
      "4 :  ('quần_vợt', 5047)\n",
      "5 :  ('tay_vợt', 5655)\n",
      "6 :  ('xuất_sắc', 7201)\n",
      "7 :  ('việt_nam', 6947)\n",
      "8 :  ('cúp', 1574)\n",
      "9 :  ('vietravel', 6912)\n",
      "10 :  ('2016', 124)\n",
      "11 :  ('chính_thức', 1196)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load dữ liệu các stopwords \n",
    "with open(\"data/vietnamese-stopwords.txt\",encoding=\"utf8\") as f:\n",
    "    stopwords = f.readlines()\n",
    "stopwords = [x.strip().replace(\" \", \"_\") for x in stopwords] \n",
    "print(\"Danh sách 10 từ dừng đầu tiên (từ không mang ý nghĩa phân loại): \", stopwords[:10])\n",
    "print()\n",
    "\n",
    "# \n",
    "# Transforming data \n",
    "# Chuyển hoá dữ liệu text về dạng vector tfidf \n",
    "#     - loại bỏ từ dừng\n",
    "#     - sinh từ điển\n",
    "module_count_vector = CountVectorizer(stop_words=stopwords)\n",
    "model_rf_preprocess = Pipeline([('vect', module_count_vector),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ])\n",
    "# Hàm thực hiện chuyển đổi dữ liệu text thành dữ liệu số dạng ma trận \n",
    "# Input: Dữ liệu 2 chiều dạng numpy.array, mảng nhãn id dạng numpy.array \n",
    "\n",
    "# Tiền xử lý với Bag of words\n",
    "data_bow = module_count_vector.fit_transform(data_train.data, data_train.target)\n",
    "# Tiền xử lý với TF-IDF\n",
    "data_tfidf = model_rf_preprocess.fit_transform(data_train.data, data_train.target)\n",
    "\n",
    "print(\"10 từ đầu tiên trong từ điển:\\n\")\n",
    "i = 0\n",
    "for k,v in module_count_vector.vocabulary_.items():\n",
    "    i+=1\n",
    "    print(i, \": \", (k, v))\n",
    "    if i > 10:\n",
    "        break \n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bqwgTiUNkebq"
   },
   "source": [
    "## Chia dữ liệu làm 2 phần training và testing \n",
    "\n",
    "- Training chiếm 80 % dữ liệu \n",
    "- Testing chiếm 20 % dữ liệu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L59agolRkebq",
    "outputId": "934cf45b-e075-417f-e36d-ff72c12e4a8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dữ liệu training =  (179, 7972) (179,)\n",
      "Dữ liệu testing =  (45, 7972) (45,)\n",
      "\n",
      "Danh sách nhãn và id tương ứng:  [(0, 'Giải trí'), (1, 'Khoa học - Công nghệ'), (2, 'Kinh tế'), (3, 'Pháp luật'), (4, 'Sức khỏe'), (5, 'Thể thao'), (6, 'Thời sự')]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# chia dữ liệu thành 2 phần sử dụng hàm train_test_split.\n",
    "test_size = 0.2\n",
    "# Bow\n",
    "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(data_bow, data_train.target, test_size=test_size, random_state=30)\n",
    "# Tf-idf\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(data_tfidf, data_train.target, test_size=test_size, random_state=30)\n",
    "\n",
    "\n",
    "# hiển thị một số thông tin về dữ liệu \n",
    "print(\"Dữ liệu training = \", X_train_bow.shape, y_train_bow.shape)\n",
    "print(\"Dữ liệu testing = \", X_test_bow.shape, y_test_bow.shape)\n",
    "\n",
    "print() \n",
    "print(\"Danh sách nhãn và id tương ứng: \", [(idx, name) for idx, name in enumerate(data_train.target_names)] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8XlfkQfPkebr"
   },
   "outputs": [],
   "source": [
    "### bài tập ### \n",
    "# yêu cầu: Hiển thị ra id, tên nhãn của 5 văn bản đầu tiên trong tập train. \n",
    "# gợi ý: lấy dữ liệu id từ biến y_train, mapping với thứ tự nằm trong mảng data_train.target_names\n",
    "###############\n",
    "# code \n",
    "\n",
    "\n",
    "###############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z3PR74Afkebs"
   },
   "source": [
    "## Training Naive Bayes model \n",
    "\n",
    "Sử dụng thư viện sklearn để xây dựng 2 mô hình \n",
    "- `naive_bayes.MultinomialNB(alpha= 0.1)`: giá trị làm mịn alpha= 0.1\n",
    "- `naive_bayes.GaussianNB()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yXT1bxAgrQEc"
   },
   "source": [
    "### Multinomial Naive Bayes\n",
    "- Sử dụng Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kByo28zMkebt",
    "outputId": "7f7979f4-1a85-430a-872f-59fe2abf5602"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Training ...\n",
      "- Train size = (179, 7972)\n",
      "- model_MNB - train complete\n"
     ]
    }
   ],
   "source": [
    "print(\"- Training ...\")\n",
    "\n",
    "\n",
    "# X_train.shape\n",
    "print(\"- Train size = {}\".format(X_train_bow.shape))\n",
    "model_MNB = naive_bayes.MultinomialNB(alpha= 0.1)\n",
    "model_MNB.fit(X_train_bow, y_train_bow)\n",
    "\n",
    "print(\"- model_MNB - train complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b3gx2ZUNr0fh"
   },
   "source": [
    "### 2.2. Gaussian Naive Bayes\n",
    "- Sử dụng TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PXs7PcZpr7oV"
   },
   "outputs": [],
   "source": [
    "### bài tập ### \n",
    "# yêu cầu: huấn luyện một mô hình Gaussian Naive Bayes tương tự như trên\n",
    "# gợi ý: naive_bayes.GaussianNB(var_smoothing=1e-3)\n",
    "###############\n",
    "# code \n",
    "\n",
    "#######################3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IN11fsCy9JQv"
   },
   "source": [
    "## Testing Naive Bayes model \n",
    "\n",
    "\n",
    "Thực hiện dự đoán nhãn cho từng văn bản trong tập test \n",
    "\n",
    "Độ đo đánh giá: \n",
    "> accuracy = tổng số văn bản dự đoán đúng  / tổng số văn bản có trong tập test  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "J-97FYLe9JQw"
   },
   "outputs": [],
   "source": [
    "# Sử dụng thư viện tính accuracy_score trong sklearn\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vF-jd2mv9JQw",
    "outputId": "14f560a9-1205-4866-fa3e-31b954521b8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Testing ...\n",
      "- Acc = 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "print(\"- Testing ...\")\n",
    "y_pred_bow = model_MNB.predict(X_test_bow)\n",
    "print(\"- Acc = {}\".format(accuracy_score(y_test_bow, y_pred_bow)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GWgRZwL5t5FS"
   },
   "outputs": [],
   "source": [
    "#Test tương tự cho GNB?\n",
    "\n",
    "###code\n",
    "\n",
    "\n",
    "##########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJOCiVq_kebw"
   },
   "source": [
    "## 5. Thực hiện sử dụng model đã được train để infer 1 văn bản mới \n",
    "- Dữ liệu mới đến ở dạng dữ liệu thô => cần tiền xử lý dữ liệu về dạng dữ_liệu_ma_trận\n",
    "- infer sử dụng hàm model.predict(dữ_liệu_ma_trận) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fxxeXRrm9JQx",
    "outputId": "918e2de5-9e99-404d-9669-4f9e5449326e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trường đại_học bách_khoa hà_nội\n"
     ]
    }
   ],
   "source": [
    "a = ViTokenizer.tokenize(\"Trường đại học bách khoa hà nội\")\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F-eLhYlvkeby",
    "outputId": "0c19f40e-e115-4b36-f5d0-4dadceac96d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Công Phượng ghi_bàn cho đội_tuyển Việt_Nam\n",
      "  (0, 1538)\t1\n",
      "  (0, 2177)\t1\n",
      "  (0, 4837)\t1\n",
      "  (0, 6947)\t1\n",
      "  (0, 7877)\t1\n",
      "\n",
      "Danh sách nhãn và id tương ứng:  [(0, 'Giải trí'), (1, 'Khoa học - Công nghệ'), (2, 'Kinh tế'), (3, 'Pháp luật'), (4, 'Sức khỏe'), (5, 'Thể thao'), (6, 'Thời sự')]\n"
     ]
    }
   ],
   "source": [
    "# tiền xử lý dữ liệu sử dụng module module_count_vector. \n",
    "van_ban_moi = ViTokenizer.tokenize(\"Công Phượng ghi bàn cho đội tuyển Việt Nam\")\n",
    "#van_ban_moi = [\"Công_phượng ghi_bàn cho đội_tuyển Việt_nam\"]\n",
    "print(van_ban_moi)\n",
    "input_data_preprocessed = module_count_vector.transform([van_ban_moi])\n",
    "print(input_data_preprocessed)\n",
    "\n",
    "print()\n",
    "print(\"Danh sách nhãn và id tương ứng: \", [(idx, name) for idx, name in enumerate(data_train.target_names)] )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nVL21His9JQz"
   },
   "outputs": [],
   "source": [
    "### bài tập ### \n",
    "# yêu cầu: dự đoán nhãn của 1 văn bản mới. Sử dụng mô hình Multinomial NB\n",
    "# gợi ý: thực hiện code suy diễn mô hình từ tiền xử lý (bước 1) => infer (bước 4). (Chú ý: không training lại - ko gọi lại hàm fit.)  \n",
    "###############\n",
    "# code \n",
    "\n",
    "\n",
    "###############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6JUggDUZ9yDE"
   },
   "source": [
    "## Quan sát độ chính xác trên tập test của GNB khi thay đổi tham số var_smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vmVcevE6-WtV"
   },
   "outputs": [],
   "source": [
    "var_smoothings = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "accs = []\n",
    "\n",
    "for var_smoothing in var_smoothings:\n",
    "  model_GNB = naive_bayes.GaussianNB(var_smoothing=1e-3)\n",
    "  model_GNB.fit(X_train_tfidf.toarray(), y_train_tfidf)\n",
    "  \n",
    "  #Hoàn thiện thêm phần code ở đây để ghi nhận acc tương ứng trong từng trường hợp\n",
    "\n",
    "  acc = #code here\n",
    "  accs.append(acc)\n",
    "\n",
    "#Minh họa tương quan bằng đồ thị::\n",
    "#Gợi ý: barplot, lineplot, ...\n",
    "\n",
    "#code here\n",
    "\n",
    "############\n",
    "\n",
    "for i in range(len(accs)):\n",
    "  print(var_smoothings[i], accs[i])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Z3PR74Afkebs"
   ],
   "name": "Naive_Bayes_Đề bài.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
